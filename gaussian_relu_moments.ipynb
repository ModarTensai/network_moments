{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "gaussian_relu_moments.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ws9isifTWuC3",
        "colab_type": "text"
      },
      "source": [
        "## Gaussian Network Moments (GNMs)\n",
        "\n",
        "Let $\\mathbf{x}\\sim\\mathcal{N}\\left(\\mathbf{\\mu}, \\mathbf{\\Sigma}\\right)$ and $q(x) = \\max(x, 0)$ where $\\Phi(x)$ and $\\varphi(x)$ are the CDF and PDF of the normal distribution,\n",
        "\n",
        "$\\mathbb{E}\\left[q(\\mathbf{x})\\right] = \\mathbf{\\mu}\\odot\\Phi\\left(\\mathbf{\\mu}\\oslash\\mathbf{\\sigma}\\right) + \\mathbf{\\sigma}\\odot\\varphi\\left(\\mathbf{\\mu}\\oslash\\mathbf{\\sigma}\\right)$\n",
        "where $\\mathbf{\\sigma} = \\sqrt{\\text{diag}\\left(\\mathbf{\\Sigma}\\right)}$ with\n",
        "$\\odot$ and $\\oslash$ as element-wise product and division.\n",
        "\n",
        "$\\mathbb{E}\\left[q^2(\\mathbf{x})\\right] = \n",
        "\\left(\\mathbf{\\mu}^2+\\mathbf{\\sigma}^2\\right) \\odot \\Phi\\left(\\mathbf{\\mu}\\oslash\\mathbf{\\sigma}\\right) + \\mathbf{\\mu} \\odot \\mathbf{\\sigma} \\odot \\varphi\\left(\\mathbf{\\mu}\\oslash\\mathbf{\\sigma}\\right)$\n",
        "where $\\text{var}\\left[q(\\mathbf{x})\\right] = \\mathbb{E}\\left[q^2(\\mathbf{x})\\right] - \\mathbb{E}\\left[q(\\mathbf{x})\\right]^2$\n",
        "\n",
        "$\\left.\\mathbb{E}\\left[q(\\mathbf{x})q(\\mathbf{x})^\\top\\right]\\right|_{\\mathbf{\\mu} = \\mathbf{0}} = c\\left(\\mathbf{\\Sigma}\\oslash\\mathbf{\\sigma}\\mathbf{\\sigma}^\\top\\right) \\odot \\mathbf{\\sigma}\\mathbf{\\sigma}^\\top$\n",
        "where $c(x) = \\frac{1}{2\\pi}\\left(x\\cos^{-1}(-x)+\\sqrt{1-x^2}\\right)$\n",
        "(Note: $\\left|c(x) - \\Phi(x - 1)\\right| < 0.0241$)\n",
        "\n",
        "$\\text{cov}\\left[q(\\mathbf{x})\\right] = \\mathbb{E}\\left[q(\\mathbf{x})q(\\mathbf{x})^\\top\\right] - \\mathbb{E}\\left[q(\\mathbf{x})\\right]\\mathbb{E}\\left[q(\\mathbf{x})\\right]^\\top$\n",
        "where $\\left.\\text{cov}\\left[q(\\mathbf{x})\\right]\\right|_{\\mathbf{\\mu} = \\mathbf{0}} = \\left.\\mathbb{E}\\left[q(\\mathbf{x})q(\\mathbf{x})^\\top\\right]\\right|_{\\mathbf{\\mu} = \\mathbf{0}} - \\frac{1}{2\\pi}\\mathbf{\\sigma}\\mathbf{\\sigma}^\\top$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv1ucF81oani",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from math import gamma, pi, sqrt\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "\n",
        "from scipy.special import hermite as scipy_hermite\n",
        "from scipy.special import gammainc as scipy_gammainc\n",
        "\n",
        "\n",
        "class GammaInc(Function):\n",
        "    \"\"\"The normalized lower incomplete gamma function.\"\"\"\n",
        "    @staticmethod\n",
        "    def forward(ctx, a, x):  # pylint: disable=unused-argument\n",
        "        \"\"\"Perform the forward pass.\"\"\"\n",
        "        ctx.a = a\n",
        "        ctx.save_for_backward(x)\n",
        "        return x.new(scipy_gammainc(a, x.data.cpu().numpy()))\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"Perform the backward pass.\"\"\"\n",
        "        x, = ctx.saved_tensors\n",
        "        return None, (-x).exp() * x ** (ctx.a - 1)\n",
        "\n",
        "gammainc = GammaInc.apply\n",
        "\n",
        "def hermite(n, x):\n",
        "    \"\"\"Evaluate the `n`th-degree Hermite polynomial.\"\"\"\n",
        "    coefficients = iter(scipy_hermite(n).coeffs.tolist())\n",
        "    out = x.new_zeros(x.size()) if torch.is_tensor(x) else 0\n",
        "    out += next(coefficients, 0)\n",
        "    for c in coefficients:\n",
        "        out *= x\n",
        "        out += c\n",
        "    return out\n",
        "\n",
        "def erf_exp_integral(a, b, c, n):\n",
        "    \"\"\"Integrate `erf(a*x+b) / exp(x**2)` from `c` to infinity.\"\"\"\n",
        "    assert isinstance(n, int) and n >= 0\n",
        "    sign_a = a.sign()\n",
        "    cond = a.abs() <= 1\n",
        "    v = a.where(cond, 1 / a)\n",
        "    x = a.where(cond, v.abs()) * 0.5\n",
        "    y = b.where(cond, -b * v)\n",
        "    z = c.where(cond, a * c + b)\n",
        "    w = c.where(cond, sign_a * z).sign()\n",
        "    series = 0\n",
        "    z_squared = z * z\n",
        "    term = lambda h, e, d: 1 / gamma(d) * x**e * hermite(h, y)\n",
        "    for i in range(n + 1):\n",
        "        s0 = term(2 * i + 1, 2 * i + 2, i + 2)\n",
        "        s1 = term(2 * i, 2 * i + 1, i + 3 / 2)\n",
        "        f0 = w * gammainc(i + 3 / 2, z_squared)\n",
        "        f1 = 1 - gammainc(i + 1, z_squared)\n",
        "        series += f0 * s0 + f1 * s1\n",
        "    neg_y = -y\n",
        "    erf_z = z.erf()\n",
        "    out = w * erf_z.abs() * neg_y.erf() + (y / (1 + v * v).sqrt()).erf()\n",
        "    out = sqrt(pi) / 2 * out + (neg_y * y).exp() * series\n",
        "    return out.where(cond, sign_a * (1 - out) - c.erf() * erf_z)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSPRwijXLf1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def approximate_integral(mean_std, correlation, cdf=None):\n",
        "    # `out` is the approximate component in computing `I`\n",
        "    sqrt(1 / pi) * \n",
        "    # I = erf_exp_integral(a, b, c, float('inf'))\n",
        "    # a = correlation / icorrelation\n",
        "    # b = sqrt(1 / 2) * mean_std / icorrelation\n",
        "    # c = -sqrt(1 / 2) * mean_std[:, None]\n",
        "    # icorrelation = sqrt(1 + correlation * correlation)\n",
        "    x = (correlation + 1) / 2\n",
        "    a = x**(1 / (2 / sqrt(pi) + 1))\n",
        "    a = a * (sqrt(2) - sqrt(pi) / 2) + sqrt(pi) / 2\n",
        "    b = (2 * x**sqrt(1 / pi)).erf()\n",
        "    b = b * sqrt(1 / 2) + (2 - sqrt(2) / 2)\n",
        "    out = (-mean_std.abs() / a).exp()**b\n",
        "    if cdf is None:\n",
        "        cdf = 1 / 2 * (1 + (mean_std * sqrt(1 / 2)).erf())\n",
        "    return sqrt(pi) * cdf - sqrt(1 / pi) * correlation.acos() * out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i54JP0Fl2fGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gaussian_relu_moments(covariance, mean=None)  # , n=10):\n",
        "    assert 0 < covariance.ndim <= 2\n",
        "    if mean is None:\n",
        "        relu_mean = 1 / sqrt(2 * pi) * std\n",
        "    if covariance.ndim == 1:  # diagonal covariance matrix\n",
        "        variance = covariance\n",
        "        std = variance.sqrt()\n",
        "        if mean is None:\n",
        "            relu_variance = 1 / 2 * variance\n",
        "            return relu_variance, relu_mean\n",
        "    else:\n",
        "        variance = covariance.diagonal()\n",
        "        std = variance.sqrt()\n",
        "        sigma = std[:, None] @ std[None, :]\n",
        "        correlation = covariance / sigma\n",
        "        if mean is None:  # or n < 0:  # zero mean\n",
        "            c = lambda x: x * (-x).acos() + (1 - x * x).sqrt() - 1\n",
        "            relu_covariance = 1 / (2 * pi) * sigma * c(correlation)\n",
        "            return relu_covariance, relu_mean\n",
        "    mean_std = mean / std\n",
        "    cdf = 1 / 2 * (1 + (mean_std * sqrt(1 / 2)).erf())\n",
        "    pdf = 1 / sqrt(2 * pi) * (-1 / 2 * mean_std * mean_std).exp()\n",
        "    std_pdf = std * pdf\n",
        "    relu_mean = mean * cdf + std_pdf\n",
        "    relu_2nd_moment = (mean * mean + variance) * cdf + mean * std_pdf\n",
        "    relu_variance = relu_2nd_moment - relu_mean * relu_mean\n",
        "    if covariance.ndim == 1:\n",
        "        return relu_variance, relu_mean\n",
        "    mu = mean[:, None] @ mean[None, :]\n",
        "    mu_std = mean[:, None] @ std[None, :]\n",
        "    relu_mu = relu_mean[:, None] @ relu_mean[None, :]\n",
        "    ir = (1 - correlation * correlation).sqrt()\n",
        "    m_sir = mean_std / ir\n",
        "    arg = m_sir.t() - m_sir * correlation\n",
        "    t1 = (mu + covariance) * (sqrt(1 / pi) * integral + cdf[:, None])\n",
        "    t2 = pdf * (1 + (arg * sqrt(0.5)).erf()) * mu_std\n",
        "    t3 = sigma * ir * (-0.5 * (arg * arg + mean_std**2)).exp()\n",
        "    relu_cross_correlation = 0.5 * (t1 + t2 + t2.t() + 1 / pi * t3)\n",
        "    relu_covariance = relu_cross_correlation - relu_mu\n",
        "    relu_covariance.diagonal().copy_(relu_variance)\n",
        "    return relu_covariance, relu_mean"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsrQh27WvAe3",
        "colab_type": "code",
        "outputId": "c8f8d8a6-0e8d-4b98-8f89-d6b061aae154",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "def rand_cov(dim, *, dtype=None, device=None):\n",
        "    \"\"\"Generate a random covariance matrix.\"\"\"\n",
        "    eigen = 1 - torch.rand(dim, dtype=dtype, device=device)\n",
        "    eigen *= (2 * dim)**0.5 / eigen.norm()\n",
        "    q, _ = torch.randn(dim, dim, dtype=dtype, device=device).qr()\n",
        "    return (q * eigen) @ q.t()\n",
        "\n",
        "def compute_moments(m, unbiased=True):\n",
        "    \"\"\"Estimate the mean and covariance given data.\"\"\"\n",
        "    mean = m.mean(-1)\n",
        "    m = m - mean[..., None]\n",
        "    fact = 1 / (m.shape[-1] - int(bool(unbiased)))\n",
        "    covariance = fact * (m @ m.transpose(-2, -1))\n",
        "    return mean, covariance\n",
        "\n",
        "mc = 1000000\n",
        "mean = torch.randn(3).double() * 2\n",
        "covariance = rand_cov(mean.size(-1), device=mean.device, dtype=mean.dtype)\n",
        "relu_covariance, relu_mean = gaussian_relu_moments(covariance, mean)\n",
        "normal = torch.distributions.MultivariateNormal(mean, covariance)\n",
        "mc_mean, mc_covariance = compute_moments(\n",
        "    normal.sample([mc]).clamp_min_(0).t())\n",
        "\n",
        "print('Test mean')\n",
        "print(relu_mean.tolist())\n",
        "print(mc_mean.tolist())\n",
        "print(torch.allclose(relu_mean, mc_mean, rtol=1e-1))\n",
        "\n",
        "print('Test variance')\n",
        "print(relu_covariance.diagonal().tolist())\n",
        "print(mc_covariance.diagonal().tolist())\n",
        "print(torch.allclose(relu_covariance.diagonal(),\n",
        "                     mc_covariance.diagonal(),\n",
        "                     rtol=1e-1, atol=1e-3))\n",
        "\n",
        "print('Test covariance')\n",
        "i, j = torch.triu_indices(mean.size(-1), mean.size(-1), 1)\n",
        "print(relu_covariance[..., i, j].tolist())\n",
        "print(mc_covariance[..., i, j].tolist())\n",
        "print(torch.allclose(relu_covariance, mc_covariance,\n",
        "                     rtol=1e-1, atol=1e-3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test mean\n",
            "[2.023749878604507, 0.03952140018354473, 1.7729310927458177]\n",
            "[2.0231033917960968, 0.03960097996071463, 1.7726876231735722]\n",
            "True\n",
            "Test variance\n",
            "[0.7228076900485041, 0.03188508095127822, 1.4355168310137292]\n",
            "[0.7225533421565001, 0.03197248546042809, 1.4344567013906944]\n",
            "True\n",
            "Test covariance\n",
            "[-0.02138807537179481, 0.17485284576809956, -0.02046914856611238]\n",
            "[-0.05886193084773982, 0.17374803049963766, -0.01998272445296804]\n",
            "[2.7520910518841295, 0.9936814567494819, 0.9762362312446333]\n",
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFt6aI43WuC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "@torch.no_grad()\n",
        "def linearize(net, x):\n",
        "    \"\"\"Compute the affine approximation for a model.\n",
        "\n",
        "    Args:\n",
        "        net: Model.\n",
        "        x: Point of approximation without batch dimension.\n",
        "\n",
        "    Returns:\n",
        "        (weights_matrix, bias_vector).\n",
        "        If `net` was a linear layer, the data of the parameters\n",
        "        will be returned instead of a computed clone (handle with care).\n",
        "\n",
        "    \"\"\"\n",
        "    assert not net.training\n",
        "    if isinstance(net, nn.Sequential) and len(net) == 1:\n",
        "        return linearize(net[0], x)\n",
        "    output = net(x.unsqueeze(0))[0]\n",
        "    if isinstance(net, nn.Linear):\n",
        "        weight = net.weight.data\n",
        "        if net.bias is None:\n",
        "            bias = weight.new_zeros(net.out_features)\n",
        "        else:\n",
        "            bias = net.bias.data\n",
        "    else:\n",
        "        x = x.repeat(output.numel(), *[1]*x.dim())\n",
        "        eye = x.new_zeros(output.numel(), output.numel())\n",
        "        eye.diagonal().fill_(1)\n",
        "        eye = eye.view(output.numel(), *output.shape)\n",
        "        with torch.enable_grad():\n",
        "            net(x.requires_grad_(True)).backward(eye)\n",
        "        weight = x.grad.view(output.numel(), -1)\n",
        "        bias = output.view(-1) - weight @ x[0].view(-1)\n",
        "    return Namespace(output=output, weight=weight, bias=bias)\n",
        "\n",
        "@torch.no_grad()\n",
        "def staged_linearization(net, x):\n",
        "    \"\"\"Linearize a sequential model around the last ReLU layer.\"\"\"\n",
        "    assert isinstance(net, nn.Sequential) and not net.training\n",
        "    assert len(net) > 2\n",
        "    for i, layer in enumerate(reversed(net)):\n",
        "        if isinstance(layer, nn.ReLU):\n",
        "            break\n",
        "    else:\n",
        "        raise ValueError('Could not find any ReLU layer')\n",
        "    a = linearize(net[:-i-1].train(False), x)\n",
        "    b = linearize(net[-i:].train(False), a.output.clamp_min_(0))\n",
        "    del a.output, b.output\n",
        "    return a, b\n",
        "\n",
        "def get_lenet(input_size=28, channles=1, num_classes=10):\n",
        "    \"\"\"Create a sequential LeNet model.\"\"\"\n",
        "    size = input_size // 4\n",
        "    return nn.Sequential(\n",
        "        nn.Conv2d(channles, 32, kernel_size=5, padding=2),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(64 * size * size, 1024),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Linear(1024, num_classes),\n",
        "    )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6SfsRn2bVeV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = get_lenet().train(False).double()\n",
        "shape = (1, 28, 28)\n",
        "mean = torch.randn(shape).view(-1).double()\n",
        "a, b = staged_linearization(net.train(False), mean.view(shape))\n",
        "cov = rand_cov(mean.numel(), device=mean.device, dtype=mean.dtype) / 20\n",
        "\n",
        "a_mean = a.weight @ mean + a.bias\n",
        "a_cov = a.weight @ cov @ a.weight.t()\n",
        "r_cov, r_mean = gaussian_relu_moments(a_cov, a_mean)\n",
        "b_mean = b.weight @ r_mean + b.bias\n",
        "b_cov = b.weight @ r_cov @ b.weight.t()\n",
        "\n",
        "mc = int(1e6)\n",
        "normal = torch.distributions.MultivariateNormal(mean, cov)\n",
        "with torch.no_grad():\n",
        "    out = net(normal.sample([mc]).view(mc, *shape)).view(mc, -1)\n",
        "o_mean, o_cov = compute_moments(out.t())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ5cgOCLpuQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(o_mean / b_mean)\n",
        "print((o_cov / b_cov).diagonal())"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}